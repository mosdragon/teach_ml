{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Handwritten Digits\n",
    "\n",
    "Example adapted from [scikit-learn docs](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "\n",
    "# Import the Multi-Layer Perceptron Classifier. This is the model we will train.\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a seed for the random number generator, we set this to make\n",
    "# reproducible results\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The handwritten digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image right now is an 8 x 8 matrix of grayscale pixel values\n",
    "# Here we print the first image's pixel values.\n",
    "print(digits.images[0])\n",
    "print(\"\\nHere are the dimensions of the first feature matrix: {}\".format(digits.images[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "print(\"Number of examples we have: {}\".format(n_samples))\n",
    "\n",
    "# Data is a list of vectors now, each vector is length 64, since the image dimensions are 8 x 8.\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "print(\"Here are the dimensions of the feature vectors stacked up together: {}\".format(data.shape))\n",
    "\n",
    "print(\"Here is the length of each feature vector X: {}\".format(data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to now create our test and train splits\n",
    "\n",
    "# We'll train on 70% of our data\n",
    "train_size = int(n_samples * 0.70)\n",
    "train_X = data[:train_size]\n",
    "train_y = digits.target[:train_size]\n",
    "print(len(train_X))\n",
    "\n",
    "# The remaining samples are for our test set\n",
    "test_size = n_samples - train_size\n",
    "test_X = data[train_size:]\n",
    "test_y = digits.target[train_size:]\n",
    "print(len(test_X))\n",
    "\n",
    "assert n_samples == (len(test_X) + len(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP: Multi-layer Perceptron Classifier\n",
    "Read the [Docs](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "You're going to test out the MLP with different parameters.\n",
    "\n",
    "First, let's do different max iteration / epoch values. An epoch is an interation, so we can limit\n",
    "the number of iterations and see it's effect on training / testing accuracy.\n",
    "\n",
    "We'll plot it at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_counts = [5, 10, 20, 50, 100, 140, 200, 500, 1000, 2000] # We'll loop over this and set the MLP max iterations to this\n",
    "classifiers = [] # Append your classifiers here after applying .fit() to them\n",
    "\n",
    "train_accs = [] # Append train accuracies here\n",
    "test_accs = [] # Append test accuracies here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_count in epoch_counts:\n",
    "    # TODO: Use the epoch_count variable here, refer to MLP docs\n",
    "    classifier = MLPClassifier(random_state=seed)\n",
    "    # TODO: Use the fit() function here\n",
    "    # TODO: Compute the accuracies below\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "    # TODO: Append the accuracies to the respective lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot the results\n",
    "plt.plot(epoch_counts, train_accs, \"g\")\n",
    "plt.plot(epoch_counts, test_accs, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this outside of Jupyter notebook,\n",
    "# uncomment this next line.\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
