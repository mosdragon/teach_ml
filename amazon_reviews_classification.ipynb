{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Amazon Reviews\n",
    "\n",
    "Now, we're going to take a deep dive into Natural Language Processing. One of the most common tasks in this domain is _sentiment analysis_, detecting whether the author had a _positive_ or _negative_ tone. We'll be applying this to a dataset of 34,000 Amazon product reviews.\n",
    "\n",
    "We'll use the text of the reviews and titles as our _features_, and we'll have 3 possible labels:\n",
    "- `positive` for all reviews of _4_ and _5_ stars\n",
    "- `neutral` for all reviews of _3_ stars\n",
    "- `negative` for all reviews of _2_ stars or below.\n",
    "\n",
    "The dataset will be at `datasets/amazon_reviews.csv`. They have been adapted from a larger dataset available from [Kaggle](https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products/version/3#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# To create test/train splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "# To help us go through different parameter configurations for\n",
    "# each type of model.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# To help us evaluate the model on each trial or \"split\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to stop the barrage of warning messages we'll get later\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seed to use later.\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import your dataset as usual\n",
    "dataset = \"datasets/amazon_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results from the table above. Does something seem off to you? If you know what [quartiles](https://www.mathsisfun.com/data/quartiles.html) are, then you should be seeing a pattern in the data from the table above.\n",
    "\n",
    "Let's get some visualizations going to help us understand what's going on. Below, we're going to group our DataFrame rows by the column we care about, `stars`. __Note:__ we're going to get rid of this column soon since we care about `neutral` vs `negative` vs `positive`, not the actual number of stars someone gave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the counts of our columns after we group them by star count\n",
    "df_star_counts = df.groupby(\"stars\").count()\n",
    "df_star_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text and title fields are effectively just counting the rows for us now. Ignoring the discrepancy in counts for text and title (this dataset is not perfect) we can see that the reviews for the products in this dataset are overwhelmingly 5's.\n",
    "\n",
    "So, this dataset is not the best because it is biased towards 4's and 5's off the bat. Consequently, we should expect that after training, any of our estimators will spit out `positive` as the prediction almost all the time. Let's crunch some numbers below to see if we could come up with a better `classifier` giving the same prediction _100%_ of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's just focus on the \"text\" column and get the values out.\n",
    "# The list we get here will be the number of examples we have with 1-star,\n",
    "# with 2-star, and so on\n",
    "counts = df_star_counts[\"text\"].values\n",
    "\n",
    "# We'll make an array with the star counts\n",
    "# So two 1's and four 2's would be: [1, 1, 2, 2, 2, 2]\n",
    "stars = []\n",
    "for idx, count in enumerate(counts):\n",
    "    star_num = idx + 1\n",
    "    stars += [star_num] * count \n",
    "\n",
    "# Here we can make a histogram of the stars. Looks like almost all the ratings are 4's or 5's\n",
    "sns.distplot(stars, kde=False, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count the total number of examples we have\n",
    "n_samples = sum(counts)\n",
    "\n",
    "# Now let's count only the \"positive\" examples, meaning 4's and 5's\n",
    "n_positive = sum(counts[3:])\n",
    "\n",
    "# TODO: Now, compute the ratio of \"positive\" examples to all examples\n",
    "positive_ratio = 0\n",
    "print(positive_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So check out the number above. It sounds absurd, but we could have a _classifier_ made that does nothing but give _positive_ for every example and we'd be hitting over 90% accuracy.\n",
    "\n",
    "Ambitious though it may be, let's see if we can actually train a true classifier to improve our accuracy above what we got for _positive_ratio_.\n",
    "\n",
    "Let's start by using a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: We need to preprocess our data. For now, we'll only be using the text and stars fields\n",
    "df = df[[\"text\", \"stars\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll build our counts of words.\n",
    "\n",
    "# This built-in will help us out\n",
    "from collections import Counter\n",
    "\n",
    "def bag_of_words(text):\n",
    "    \"\"\"\n",
    "    TODO: \n",
    "    1. Lowercase everything in the text\n",
    "    2. Split up the text into words, and make a list called \"words\" that holds all the words\n",
    "    3. Make sure all the words are lower-case and that you account for punctuation.\n",
    "    Ex: \"awesome!\" is not one \"word\", it's really \"awesome\" and \"!\".\n",
    "    4. Finally, return Counter(words), which will be a dictionary with counts of the occurence\n",
    "    of each word\n",
    "    \"\"\"\n",
    "    punctuation = [\".\", \",\", \"(\", \")\", \"'\", \":\", \";\", '\"', \"\\\\\"] # HINT: filter these out\n",
    "    words = []\n",
    "    return Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, pluck out the dataframe's \"text\" column values\n",
    "text_vals = df[\"text\"].values\n",
    "text_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bag_of_words to the functions and store those in a list called bows.\n",
    "bows = []\n",
    "for text in text_vals:\n",
    "    bow = bag_of_words(text)\n",
    "    bows.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, now we have the bag of words for ALL text in our dataset. Let's build a vocabulary out of this\n",
    "# Each bow is a Counter object, so we want to keep the total occurences of words in the dataset\n",
    "\n",
    "word_occurences = Counter()\n",
    "\n",
    "for bow in bows:\n",
    "    word_occurences.update(bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's filter out the words that have at least 10 occurences\n",
    "vocab = set()\n",
    "removed_vocab = set()\n",
    "\n",
    "for word, count in word_occurences.items():\n",
    "    if  count >= 10:\n",
    "        vocab.add(word)\n",
    "    else:\n",
    "        removed_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which words we removed\n",
    "print(len(removed_vocab))\n",
    "removed_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's see how many words we kept\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we create a bag_of_words_using_vocab function that does the same thing as\n",
    "# bag_of_words above except we remove any words that are not in the vocab set\n",
    "\n",
    "def bag_of_words_using_vocab(text, vocabulary=vocab):\n",
    "    bow = bag_of_words(text)\n",
    "    words = list(bow.keys())\n",
    "    for word in words:\n",
    "        if word not in vocabulary:\n",
    "            bow.pop(word)\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, use bag_of_words_using_vocab to create new bows\n",
    "better_bows = []\n",
    "\n",
    "for text in text_vals:\n",
    "    better_bow = bag_of_words_using_vocab(text, vocabulary=vocab)\n",
    "    better_bows.append(better_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's take a look at what's left in the bag of words now\n",
    "better_bows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets create vectors out of these new bags of words\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# We now have these as our X vectors\n",
    "vectorizer = DictVectorizer()\n",
    "X = vectorizer.fit_transform(better_bows)\n",
    "\n",
    "# This is not a DataFrame, so we can't do X.head()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_stars = df[\"stars\"].values\n",
    "# This is not a DataFrame, so we can't do y_stars.head()\n",
    "y_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "for stars in y_stars:\n",
    "    if stars >= 4:\n",
    "        y.append(\"positive\")\n",
    "    elif stars == 3:\n",
    "        y.append(\"neutral\")\n",
    "    else:\n",
    "        y.append(\"negative\")\n",
    "\n",
    "# This is not a DataFrame, so we can't do y.head()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split into test, train\n",
    "# We want 70% train, 30% test\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Estimators\n",
    "\n",
    "Use these two algorithms:\n",
    "- [Neural Network](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "- [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "__DO NOT DO CROSS VALIDATION__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation\n",
    "\n",
    "Evaluate how well we did using Confusion matrices and accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Improve the Model\n",
    "\n",
    "Try these approaches to improve your model:\n",
    "- Try changing the minimum occurences we want to have to something else, see if results improve\n",
    "- Try removing useless words. Call these words \"stop-words\" in a list and prune them out of the vocab.\n",
    "  - Ex: \"the\", \"me\", \"you\", \"a\"\n",
    "- Try a different model and see if your accuracy improves (you can use CV at this point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
