{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Handwritten Digits\n",
    "\n",
    "Example adapted from [scikit-learn docs](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "\n",
    "# Import the Multi-Layer Perceptron Classifier. This is the model we will train.\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a seed for the random number generator, we set this to make\n",
    "# reproducible results\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The handwritten digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Each image right now is a 20 x 20 matrix of grayscale pixel values\n",
    "# Here we print the first image's pixel values.\n",
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "print(n_samples)\n",
    "\n",
    "# Data is a list of vectors now, each vector is length 400, since the image dimensions are 20 x 20.\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257\n",
      "540\n"
     ]
    }
   ],
   "source": [
    "# We need to now create our test and train splits\n",
    "\n",
    "# We'll train on 70% of our data\n",
    "train_size = int(n_samples * 0.70)\n",
    "train_X = data[:train_size]\n",
    "train_y = digits.target[:train_size]\n",
    "print(len(train_X))\n",
    "\n",
    "# The remaining samples are for our test set\n",
    "test_size = n_samples - train_size\n",
    "test_X = data[train_size:]\n",
    "test_y = digits.target[train_size:]\n",
    "print(len(test_X))\n",
    "\n",
    "assert n_samples == (len(test_X) + len(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP: Multi-layer Perceptron Classifier\n",
    "Read the [Docs](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we initialize a classifier object and fit it to our training set\n",
    "# TODO: Look at docs and add additional params here to try to increase\n",
    "# accuracy after you go through the demo end-to-end.\n",
    "classifier = MLPClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fit() function is how we train the classifier\n",
    "classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== AFTER TRAINING ====================\n",
      "Train Error: 1.0\n",
      "Test Error: 0.9351851851851852\n"
     ]
    }
   ],
   "source": [
    "# Now that we've finished training, get the test and train errors.\n",
    "print(\"==================== AFTER TRAINING ====================\")\n",
    "\n",
    "train_error = classifier.score(train_X, train_y)\n",
    "print(\"Train Error: {}\".format(train_error))\n",
    "\n",
    "test_error = classifier.score(test_X, test_y)\n",
    "print(\"Test Error: {}\".format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the classifier to make predictions on the test set using only the \n",
    "# features, not the labels\n",
    "predicted = classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.94        53\n",
      "          1       0.98      0.91      0.94        53\n",
      "          2       1.00      0.98      0.99        53\n",
      "          3       0.96      0.85      0.90        53\n",
      "          4       0.95      0.91      0.93        57\n",
      "          5       0.93      0.98      0.96        56\n",
      "          6       0.93      1.00      0.96        54\n",
      "          7       0.94      0.93      0.93        54\n",
      "          8       0.88      0.88      0.88        52\n",
      "          9       0.87      0.95      0.90        55\n",
      "\n",
      "avg / total       0.94      0.94      0.94       540\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Look up what precision, recall, and f1-score are.\n",
    "# Explain why recall for 3 and 8 might be so low.\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(test_y, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[51  0  0  0  1  0  1  0  0  0]\n",
      " [ 2 48  0  1  0  0  0  0  0  2]\n",
      " [ 0  0 52  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 45  0  2  0  1  5  0]\n",
      " [ 0  0  0  0 52  0  2  2  0  1]\n",
      " [ 0  0  0  0  0 55  1  0  0  0]\n",
      " [ 0  0  0  0  0  0 54  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  4]\n",
      " [ 1  1  0  0  2  1  0  0 46  1]\n",
      " [ 1  0  0  0  0  1  0  0  1 52]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Try to interpret what this might be.\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(test_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's nice to see visual representation of the results\n",
    "images_and_predictions = list(zip(digits.images[train_size:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this outside of Jupyter notebook,\n",
    "# uncomment this next line.\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
