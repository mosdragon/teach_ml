{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cross-Validation\n",
    "\n",
    "Here, we'll go through how to use cross-validation for your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# To create test/train splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "# To help us go through different parameter configurations for\n",
    "# each type of model.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# To help us evaluate the model on each trial or \"split\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to stop the barrage of warning messages we'll get later\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seed to use later.\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import your dataset as usual\n",
    "dataset = \"datasets/people.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how big our dataset is\n",
    "n_samples, n_columns = df.shape\n",
    "print(\"Number of samples: {}\".format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create visualization\n",
    "sns.pairplot(df, hue=\"Gender\", height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Separate features and labels\n",
    "df_X = df.drop(\"Gender\", axis=1)\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df[\"Gender\"]\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split into test, train\n",
    "# We want 70% train, 30% test\n",
    "train_X, test_X, train_y, test_y = train_test_split(df_X, df_y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Estimators\n",
    "\n",
    "To demonstrate how to do crossfold-validation (CV), we'll use two algorithms:\n",
    "- [Neural Network](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "- [KNN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "\n",
    "Here's what we'll be doing:\n",
    "- Defining a \"grid\" of possibilities for the models' parameters\n",
    "- Training on \"splits\" of our data\n",
    "- Keeping the best model of each type (KNN, NN) that performed best on our dataset\n",
    "- Showing the accuracies and confusion matrices of those best-performing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__JUPYTER PRO-TIP__: You can time the run-time of individual cells in Jupyter by putting `%time` at the start of any cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# We're going to build nn_params, a list of dictionaries\n",
    "# Each dictionary has the variable name to try modifying, and\n",
    "# which values to try for it.\n",
    "# All combinations of variables in the dictionary below will be tried\n",
    "\n",
    "nn_params = [\n",
    "    {\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (50,), (100,), # models with 1 hidden layer\n",
    "            (50,50), (100,100), # models with 2 hidden layers\n",
    "        ],\n",
    "        \"max_iter\": [100, 200, 500],\n",
    "        \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "        \"learning_rate_init\": [1e-5, 1e-4, 1e-3],\n",
    "    },\n",
    "    {\n",
    "        \"max_iter\": [100, 200],\n",
    "        \"activation\": [\"tanh\"],\n",
    "        \"learning_rate_init\": [1e-5, 1e-4],\n",
    "    }\n",
    "]\n",
    "\n",
    "# nn_tester will test the permutations of parameters in nn_params\n",
    "# using 5 trials (splitting train set into 5, training on 4 and testing\n",
    "# on the 5th).\n",
    "nn_model = MLPClassifier(random_state=seed)\n",
    "nn_experimenter = GridSearchCV(nn_model, nn_params, cv=5)\n",
    "nn_experimenter.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameter set found: \")\n",
    "print(nn_experimenter.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = nn_experimenter.cv_results_['mean_test_score']\n",
    "param_configurations = nn_experimenter.cv_results_['params']\n",
    "\n",
    "for mean, params_configuration in zip(means, param_configurations):\n",
    "    print(\"Avg accuracy: {}\\tModel: {}\".format(mean, params_configuration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = nn_experimenter.score(train_X, train_y)\n",
    "test_acc = nn_experimenter.score(test_X, test_y)\n",
    "\n",
    "print(\"Train accuracy: {:.1f}%\".format(train_acc*100))\n",
    "print(\"Test accuracy: {:.1f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "nn_best_preds = nn_experimenter.predict(test_X)\n",
    "nn_conf_mat = confusion_matrix(test_y, nn_best_preds)\n",
    "\n",
    "sns.heatmap(nn_conf_mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('Actual label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# Now we can do the same thing with KNN\n",
    "\n",
    "# Notice here how we decide we only want one dictionary of params\n",
    "# to try all permutations of.\n",
    "knn_params = [\n",
    "    {\n",
    "        \"n_neighbors\": [2, 3, 4, 5, 10, 12, 15],\n",
    "        \"p\": [1, 2],\n",
    "        \"algorithm\": [\"ball_tree\", \"kd_tree\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_exp = GridSearchCV(knn_model, knn_params, cv=5)\n",
    "\n",
    "knn_exp.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameter set found: \")\n",
    "print(knn_exp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means = knn_exp.cv_results_['mean_test_score']\n",
    "param_configurations = knn_exp.cv_results_['params']\n",
    "\n",
    "for mean, params_configuration in zip(means, param_configurations):\n",
    "    print(\"Avg accuracy: {}\\tModel: {}\".format(mean, params_configuration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = knn_exp.score(train_X, train_y)\n",
    "test_acc = knn_exp.score(test_X, test_y)\n",
    "\n",
    "print(\"Train accuracy: {:.1f}%\".format(train_acc*100))\n",
    "print(\"Test accuracy: {:.1f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "knn_best_preds = knn_exp.predict(test_X)\n",
    "knn_conf_mat = confusion_matrix(test_y, knn_best_preds)\n",
    "\n",
    "sns.heatmap(knn_conf_mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('Actual label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
